{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Activation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2QjN6QnHS1OneiZaGHz4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HabibMbow94/Convolution_Neural_Network/blob/main/Activation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRAIRIES AND DATASETS\n",
        "___"
      ],
      "metadata": {
        "id": "BrG-smePLtNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import imageio\n",
        "from tqdm import tqdm \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import skimage.transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from IPython import display\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "6J3OEAPyNRZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the function hyperbolic tangent\n",
        "def sigmoid_f(x):\n",
        "  sigmoid = 1/(1 + torch.exp(-x))\n",
        "  return sigmoid\n",
        "\n",
        "# define the function derivate hyperbolic tangent\n",
        "def d_sigmoid_f(x):\n",
        "  d_sigmoid = sigmoid_f(x)*(1-sigmoid_f(x))\n",
        "  return d_sigmoid"
      ],
      "metadata": {
        "id": "ez290_SxDX3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the function hyperbolic tangent\n",
        "def tanh_f(x):\n",
        "  tan_h = (torch.exp(x) - torch.exp(-x))/(torch.exp(x) + torch.exp(-x))\n",
        "  return tan_h\n",
        "\n",
        "# define the function derivate hyperbolic tangent\n",
        "def dtanh(x):\n",
        "  d_tan_h = 1 - torch.square(tanh_f(x))\n",
        "  return d_tan_h"
      ],
      "metadata": {
        "id": "m1bchMCFiu-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #define the function hyperbolic tangent \n",
        "def reLU_f(x):\n",
        "  relu = torch.where(x>0, x, 0)\n",
        "  relu.detach().numpy()\n",
        "  print(relu.dtype)\n",
        "  return relu\n",
        "\n",
        "# # define the function derivate hyperbolic tangent\n",
        "# def d_reLU_f(x):\n",
        "#   d_relu = torch.max(0, 1)\n",
        "#   return d_relu"
      ],
      "metadata": {
        "id": "9p167KdxBuYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swish(x):\n",
        "  \n",
        "  return x*sigmoid_f(x)\n",
        "\n",
        "def d_swish(x):\n",
        "  \n",
        "  d = sigmoid_f(x) + x*sigmoid_f(x)*(1 - swish(x))\n",
        "  return d"
      ],
      "metadata": {
        "id": "Hhllofcrfpn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softplus(x):\n",
        "  return torch.log(1+torch.exp(x))\n",
        "\n",
        "def mish(x):\n",
        " \n",
        "  return x*tanh_f(softplus(x))\n",
        "\n",
        "def d_mish(beta,x):\n",
        "  \n",
        "  d= mish(x)/x +x*sigmoid_f(x)*(1 - torch.square(tanh_f(softplus(x))))\n",
        "  return d"
      ],
      "metadata": {
        "id": "kyvxfKJWgAkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Dataset__\n",
        "Load MNIST and define train/test functions as before. Please make sure you read the code carefully and understand what it is doing."
      ],
      "metadata": {
        "id": "vYHZkF6cME-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Load the training and test dataset.\n",
        "mnist_train = datasets.MNIST(\n",
        "    \"/tmp/mnist\", train=True, download=True, transform=transforms.ToTensor()\n",
        ")\n",
        "mnist_test = datasets.MNIST(\n",
        "    \"/tmp/mnist\", train=False, download=True, transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# Size of the batches the data loader will produce.\n",
        "batch_size = 64\n",
        "\n",
        "# This creates the dataloaders.\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    mnist_train, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    mnist_test, batch_size=batch_size, shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "5OODSU_-NYXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch, targets = iter(train_loader).next()\n",
        "image, target = batch[0], targets[0]\n",
        "print(\"Size of the image:\", image.size())"
      ],
      "metadata": {
        "id": "awr912B6OmkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "C9WOK95HhSNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "4K0hzWodU4VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#definie the train function\n",
        "def train(model, criterion, data_loader, optimizer, num_epochs):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\"\n",
        "\n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "\n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "\n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "\n",
        "    # Loop over epochs.\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "\n",
        "        # Loop over data.\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "\n",
        "            # Forward pass.\n",
        "            output = model(data.to(device))\n",
        "            loss = criterion(output.to(device), target.to(device))\n",
        "\n",
        "            # Backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # NOTE: It is important to call .item() on the loss before summing.\n",
        "            if ema_loss is None:\n",
        "                ema_loss = loss.item()\n",
        "            else:\n",
        "                ema_loss += (loss.item() - ema_loss) * 0.01\n",
        "\n",
        "        # Print out progress the end of epoch.\n",
        "        print(\n",
        "            \"Train Epoch: {} \\ttrain Loss: {:.6f}\".format(epoch, ema_loss),\n",
        "        )\n",
        "\n",
        "\n",
        "def test(model, data_loader, name_of_ac, use_pytorch):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Loop over test data.\n",
        "        for data, target in data_loader:\n",
        "\n",
        "            # Forward pass.\n",
        "            output = model(data.to(device))\n",
        "\n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            # Count number of correct predictions.\n",
        "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # Print test accuracy.\n",
        "    percent = 100.0 * correct / len(data_loader.dataset)\n",
        "    \n",
        "    print(f\"Accuracy from {name_of_ac.upper()} activation function \"+ (\"using\" if use_pytorch else \"without\" )+ f\" pytorch implementation : {correct} / {len(data_loader.dataset)} ({percent:.0f}%)\")\n",
        "    print(\"\\n\"*3)"
      ],
      "metadata": {
        "id": "xqoE2ZsAP3Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLEMENTATION THE CONVOLUTIONAL NEURAL NETWORK"
      ],
      "metadata": {
        "id": "jfAeDt-pi0ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "  \"\"\"Simple convolutional network.\"\"\"\n",
        "\n",
        "  def __init__(self, image_side_size, num_classes, act_fc, use_pytorch_ac = False, in_channels=1):\n",
        "    super().__init__()\n",
        "    AC = {\"relu\":reLU_f, \"tanh\" : tanh_f, \"swish\": swish, \"mish\": mish}\n",
        "    AC_pytorch = {\"relu\":F.relu, \"tanh\" : F.tanh, \"swish\": F.silu, \"mish\": F.mish}\n",
        "    self.conv1 = nn.Conv2d(in_channels,image_side_size, 3,2,3)\n",
        "    self.conv2 = nn.Conv2d(image_side_size, image_side_size,3,1,3)\n",
        "    self.conv3 = nn.Conv2d(image_side_size,2*image_side_size, 3,1,2)\n",
        "    self.conv4 = nn.Conv2d(2*image_side_size,2*image_side_size,3,1,1)\n",
        "    self.conv5 = nn.Conv2d(2*image_side_size,1,3,1,0)\n",
        "    self.linear = nn.Linear((image_side_size-8)*(image_side_size-8), num_classes)\n",
        "    self.activation_functions = AC_pytorch[act_fc] if use_pytorch_ac else AC[act_fc]\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    print(x.size())\n",
        "    x = self.activation_functions(x)\n",
        "    x = self.activation_functions(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.activation_functions(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.activation_functions(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.activation_functions(x)\n",
        "    x = self.linear(x.view(x.size(0), -1))\n",
        "    return x\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "WgUe7boWouIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(a_f, use_pytorch = False):\n",
        "  conv_model = DNN(28, 10, act_fc = a_f, use_pytorch_ac = use_pytorch)\n",
        "  optimizer = torch.optim.SGD(conv_model.parameters(), lr=0.01, momentum=0.9)\n",
        "  train(conv_model, criterion, train_loader, optimizer, num_epochs=10)\n",
        "  test(conv_model, test_loader,name_of_ac=a_f, use_pytorch=use_pytorch)"
      ],
      "metadata": {
        "id": "0iay4-ELSr7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a_c in ['tanh','relu','swish','mish']:\n",
        "  my_function(a_c, use_pytorch=True)"
      ],
      "metadata": {
        "id": "M1NIk1j3Tdgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "\n",
        "num_epochs=5 \n",
        "\n",
        "\n",
        "\n",
        "0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
        "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
        " 20%|██        | 1/5 [00:16<01:05, 16.35s/it]Train Epoch: 0 \ttrain Loss: 0.288599\n",
        " 40%|████      | 2/5 [00:32<00:48, 16.20s/it]Train Epoch: 1 \ttrain Loss: 0.185475\n",
        " 60%|██████    | 3/5 [00:48<00:32, 16.14s/it]Train Epoch: 2 \ttrain Loss: 0.123489\n",
        " 80%|████████  | 4/5 [01:04<00:16, 16.25s/it]Train Epoch: 3 \ttrain Loss: 0.110499\n",
        "100%|██████████| 5/5 [01:20<00:00, 16.19s/it]Train Epoch: 4 \ttrain Loss: 0.074640\n",
        "\n",
        "Accuracy from TANH activation function using pytorch implementation : 9769 / 10000 (97.6900%)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " 20%|██        | 1/5 [00:16<01:04, 16.14s/it]Train Epoch: 0 \ttrain Loss: 0.190975\n",
        " 40%|████      | 2/5 [00:32<00:48, 16.17s/it]Train Epoch: 1 \ttrain Loss: 0.112485\n",
        " 60%|██████    | 3/5 [00:48<00:32, 16.11s/it]Train Epoch: 2 \ttrain Loss: 0.080574\n",
        " 80%|████████  | 4/5 [01:04<00:16, 16.03s/it]Train Epoch: 3 \ttrain Loss: 0.067419\n",
        "100%|██████████| 5/5 [01:20<00:00, 16.07s/it]Train Epoch: 4 \ttrain Loss: 0.057721\n",
        "\n",
        "Accuracy from RELU activation function using pytorch implementation : 9832 / 10000 (98.3200%)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " 20%|██        | 1/5 [00:16<01:05, 16.37s/it]Train Epoch: 0 \ttrain Loss: 2.300586\n",
        " 40%|████      | 2/5 [00:32<00:48, 16.14s/it]Train Epoch: 1 \ttrain Loss: 0.284398\n",
        " 60%|██████    | 3/5 [00:48<00:32, 16.06s/it]Train Epoch: 2 \ttrain Loss: 0.108999\n",
        " 80%|████████  | 4/5 [01:04<00:16, 16.04s/it]Train Epoch: 3 \ttrain Loss: 0.087341\n",
        "100%|██████████| 5/5 [01:20<00:00, 16.10s/it]Train Epoch: 4 \ttrain Loss: 0.063580\n",
        "\n",
        "Accuracy from SWISH activation function using pytorch implementation : 9799 / 10000 (97.9900%)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " 20%|██        | 1/5 [00:17<01:09, 17.50s/it]Train Epoch: 0 \ttrain Loss: 0.485544\n",
        " 40%|████      | 2/5 [00:33<00:50, 16.82s/it]Train Epoch: 1 \ttrain Loss: 0.143080\n",
        " 60%|██████    | 3/5 [00:50<00:33, 16.54s/it]Train Epoch: 2 \ttrain Loss: 0.089500\n",
        " 80%|████████  | 4/5 [01:06<00:16, 16.40s/it]Train Epoch: 3 \ttrain Loss: 0.075455\n",
        "100%|██████████| 5/5 [01:22<00:00, 16.44s/it]Train Epoch: 4 \ttrain Loss: 0.057078\n",
        "\n",
        "Accuracy from MISH activation function using pytorch implementation : 9801 / 10000 (98.0100%)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "d3foEszJMLHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the function hyperbolic tangent\n",
        "def reLU_f(x):\n",
        "  # relu = torch.tensor(torch.where(x>0, x, 0))\n",
        "  relu= x if x>0 else 0\n",
        "  relu.cpu().numpy()\n",
        "  # print(relu.dtype)\n",
        "  return relu\n",
        "\n",
        "# define the function derivate hyperbolic tangent\n",
        "def d_reLU_f(x):\n",
        "  d_relu = torch.max(0, 1)\n",
        "  return d_relu"
      ],
      "metadata": {
        "id": "zh03buasFN-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reLU_f(1)"
      ],
      "metadata": {
        "id": "C_W3s66XGa0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a_c in ['tanh','swish','mish']:\n",
        "  my_function(a_c, use_pytorch=False)"
      ],
      "metadata": {
        "id": "MkDiVgyHYLd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "\n",
        "for a_c in ['tanh','swish','mish']:\n",
        "  my_function(a_c, use_pytorch=False)\n",
        "\n",
        "  \n",
        "\n",
        " 20%|██        | 1/5 [00:16<01:06, 16.67s/it]Train Epoch: 0 \ttrain Loss: 0.313319\n",
        " 40%|████      | 2/5 [00:33<00:49, 16.62s/it]Train Epoch: 1 \ttrain Loss: 0.292987\n",
        " 60%|██████    | 3/5 [00:50<00:33, 16.73s/it]Train Epoch: 2 \ttrain Loss: 0.273542\n",
        " 80%|████████  | 4/5 [01:07<00:16, 16.92s/it]Train Epoch: 3 \ttrain Loss: 0.267651\n",
        "100%|██████████| 5/5 [01:24<00:00, 16.82s/it]Train Epoch: 4 \ttrain Loss: 0.256078\n",
        "\n",
        "Accuracy from TANH activation function without pytorch implementation : 9229 / 10000 (92.2900%)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " 20%|██        | 1/5 [00:15<01:03, 15.78s/it]Train Epoch: 0 \ttrain Loss: 0.344519\n",
        " 40%|████      | 2/5 [00:30<00:46, 15.36s/it]Train Epoch: 1 \ttrain Loss: 0.311537\n",
        " 60%|██████    | 3/5 [00:45<00:30, 15.26s/it]Train Epoch: 2 \ttrain Loss: 0.296040\n",
        " 80%|████████  | 4/5 [01:00<00:15, 15.14s/it]Train Epoch: 3 \ttrain Loss: 0.287173\n",
        "100%|██████████| 5/5 [01:15<00:00, 15.17s/it]Train Epoch: 4 \ttrain Loss: 0.284760\n",
        "\n",
        "Accuracy from SWISH activation function without pytorch implementation : 9216 / 10000 (92.1600%)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " 20%|██        | 1/5 [00:17<01:11, 17.80s/it]Train Epoch: 0 \ttrain Loss: 0.322612\n",
        " 40%|████      | 2/5 [00:35<00:53, 17.91s/it]Train Epoch: 1 \ttrain Loss: 0.299359\n",
        " 60%|██████    | 3/5 [00:53<00:35, 17.70s/it]Train Epoch: 2 \ttrain Loss: 0.266518\n",
        " 80%|████████  | 4/5 [01:10<00:17, 17.59s/it]Train Epoch: 3 \ttrain Loss: 0.270700\n",
        "100%|██████████| 5/5 [01:28<00:00, 17.60s/it]Train Epoch: 4 \ttrain Loss: 0.256243\n",
        "\n",
        "Accuracy from MISH activation function without pytorch implementation : 9283 / 10000 (92.8300%)\n",
        "```"
      ],
      "metadata": {
        "id": "2kF2mPRLv1Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pxzJ8T9Nv4TT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}